{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download label mapping\n",
    "\n",
    "task = f'sentiment'\n",
    "\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keys','r') as key_file:\n",
    "    key = key_file.readline().strip()\n",
    "    secret = key_file.readline().strip()\n",
    "    bearer = key_file.readline().strip()\n",
    "\n",
    "client = tweepy.Client(bearer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nike', 'adidas', 'mcdonalds', 'starbucks', 'samsung', 'apple']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this a data source, given by any entity that uses the service\n",
    "subjects = []\n",
    "with open('subjects.txt','r') as subjects_file:\n",
    "    subjects = [x.strip() for x in subjects_file.readlines()]\n",
    "\n",
    "subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case: Starbucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    "\n",
    "    text = text.replace('\\n',' ')\n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "\n",
    "    new_text = \" \".join(new_text)\n",
    "\n",
    "    new_text = new_text.replace(\"@user\",\"\").strip()\n",
    "    new_text = new_text.replace(\"http\",\"\").strip()\n",
    "    new_text = new_text.replace(\"&amp;\",\" and \").strip() # caveat\n",
    "\n",
    "    return new_text\n",
    "\n",
    "def dummy_sentiment(data, labels):\n",
    "\n",
    "    scores = np.random.dirichlet(np.ones(3),size=(data.shape[0]))\n",
    "    np.random.shuffle(scores)\n",
    "\n",
    "    data['sentiment']=[labels[x] for x in np.argmax(scores,axis=1)]\n",
    "    data['negative']=scores[:,0]\n",
    "    data['neutral']=scores[:,1]\n",
    "    data['positive']=scores[:,2]\n",
    "\n",
    "    return data\n",
    "\n",
    "def fetch_tt_data(brand,query='', size='small', days=0, save=False, dummy=False, labels=[]):\n",
    "    '''\n",
    "    Fetch recent twitter data\n",
    "    ---\n",
    "    query:\n",
    "    size:\n",
    "    days: int\n",
    "        Minimum tweet age. E.g., if days=2, will fetch tweets that are at least 2 days old, and up to a maximum of 7\n",
    "    '''\n",
    "\n",
    "    sizes = {\n",
    "        'small': 10000,\n",
    "        'medium': 50000,\n",
    "        'large': 100000\n",
    "    }\n",
    "\n",
    "    #query = '(@starbucks OR starbucks)'\n",
    "\n",
    "    end_time = pd.to_datetime(pd.Timestamp.now()-pd.to_timedelta(10,unit='s')) # mandatory\n",
    "    if days > 0:\n",
    "        end_time -= pd.to_timedelta(days, unit='days')\n",
    "\n",
    "    count = 100\n",
    "\n",
    "    tweets = tweepy.Paginator(\n",
    "        client.search_recent_tweets, \n",
    "        query=query,\n",
    "        max_results=count,\n",
    "        end_time= end_time,\n",
    "        tweet_fields=['created_at','public_metrics']\n",
    "    ).flatten(limit=sizes[size])\n",
    "\n",
    "    df = pd.DataFrame(data=[t for t in tweets])\n",
    "\n",
    "    if 'withheld' in df: #  remove withheld content\n",
    "        df = df[df['withheld'].isnull()]\n",
    "\n",
    "    df['text'] = df['text'].astype(str)\n",
    "    df['text_tokenized'] = [preprocess(t) for t in df['text'].values]\n",
    "    df['brand']=brand\n",
    "    df[['retweets','likes']]=df['public_metrics'].apply(pd.Series)[['retweet_count','like_count']]\n",
    "    \n",
    "    columns_to_drop = ['edit_history_tweet_ids','public_metrics']\n",
    "\n",
    "    if 'withheld' in df.columns:\n",
    "        columns_to_drop.append('withheld')\n",
    "\n",
    "    df = df.drop(columns=columns_to_drop, axis=0)\n",
    "\n",
    "    if (dummy):\n",
    "        df = dummy_sentiment(df, labels)\n",
    "\n",
    "    if (save):\n",
    "        df_save = df.drop(columns=['text'], axis=1)\n",
    "        df.to_csv(f'datasets/tweets_{brand}_{size}.csv',sep=',', index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>brand</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-21 00:37:53+00:00</td>\n",
       "      <td>1594490245780836352</td>\n",
       "      <td>@crisperstorm I think it's more of a call back...</td>\n",
       "      <td>I think it's more of a call back to when infin...</td>\n",
       "      <td>sony</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.093658</td>\n",
       "      <td>0.243139</td>\n",
       "      <td>0.663203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-21 00:37:51+00:00</td>\n",
       "      <td>1594490239476764678</td>\n",
       "      <td>I finally got around to watching #Morbius aaaa...</td>\n",
       "      <td>I finally got around to watching #Morbius aaaa...</td>\n",
       "      <td>sony</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.253376</td>\n",
       "      <td>0.188635</td>\n",
       "      <td>0.557989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-21 00:36:37+00:00</td>\n",
       "      <td>1594489927366021120</td>\n",
       "      <td>@BirkinWill @psychonauts8 @MarcinIsHere I'd gu...</td>\n",
       "      <td>I'd guess PS has a mid-gen refresh first. It'l...</td>\n",
       "      <td>sony</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.689539</td>\n",
       "      <td>0.307065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-21 00:36:00+00:00</td>\n",
       "      <td>1594489771643895808</td>\n",
       "      <td>@ElijahYak @Robert0726Rolfe @xMBGx I don’t giv...</td>\n",
       "      <td>I don’t give a SHIT about the praises Sony for...</td>\n",
       "      <td>sony</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.919803</td>\n",
       "      <td>0.007504</td>\n",
       "      <td>0.072694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-21 00:34:26+00:00</td>\n",
       "      <td>1594489375819268104</td>\n",
       "      <td>@getFANDOM WE dont want nor need this, WE want...</td>\n",
       "      <td>WE dont want nor need this, WE want Marvel Stu...</td>\n",
       "      <td>sony</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.382888</td>\n",
       "      <td>0.349801</td>\n",
       "      <td>0.267311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id  \\\n",
       "0 2022-11-21 00:37:53+00:00  1594490245780836352   \n",
       "1 2022-11-21 00:37:51+00:00  1594490239476764678   \n",
       "2 2022-11-21 00:36:37+00:00  1594489927366021120   \n",
       "3 2022-11-21 00:36:00+00:00  1594489771643895808   \n",
       "4 2022-11-21 00:34:26+00:00  1594489375819268104   \n",
       "\n",
       "                                                text  \\\n",
       "0  @crisperstorm I think it's more of a call back...   \n",
       "1  I finally got around to watching #Morbius aaaa...   \n",
       "2  @BirkinWill @psychonauts8 @MarcinIsHere I'd gu...   \n",
       "3  @ElijahYak @Robert0726Rolfe @xMBGx I don’t giv...   \n",
       "4  @getFANDOM WE dont want nor need this, WE want...   \n",
       "\n",
       "                                      text_tokenized brand  retweets  likes  \\\n",
       "0  I think it's more of a call back to when infin...  sony         0      0   \n",
       "1  I finally got around to watching #Morbius aaaa...  sony         0      0   \n",
       "2  I'd guess PS has a mid-gen refresh first. It'l...  sony         1      3   \n",
       "3  I don’t give a SHIT about the praises Sony for...  sony         0      0   \n",
       "4  WE dont want nor need this, WE want Marvel Stu...  sony         0      1   \n",
       "\n",
       "  sentiment  negative   neutral  positive  \n",
       "0  positive  0.093658  0.243139  0.663203  \n",
       "1  positive  0.253376  0.188635  0.557989  \n",
       "2   neutral  0.003396  0.689539  0.307065  \n",
       "3  negative  0.919803  0.007504  0.072694  \n",
       "4  negative  0.382888  0.349801  0.267311  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemplify\n",
    "df = fetch_tt_data(\n",
    "    brand='sony',\n",
    "    query = 'entity:\"sony\" -is:retweet lang:en -from:sony',\n",
    "    days=2,\n",
    "    dummy=True,\n",
    "    labels=labels,\n",
    "    save=True\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://postgres:f532430fbb@localhost:5432/feedbaq')\n",
    "\n",
    "def export_to_db(data, engine, table_name=\"tweets\"):\n",
    "\n",
    "    # format for database\n",
    "    data = data.drop(['text'], axis=1)\n",
    "\n",
    "    data = data.rename(\n",
    "        columns={\n",
    "            'id':'tweet_id',\n",
    "            'text_tokenized':'text'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    data.to_sql(table_name, engine, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_db(df,engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer_sentiment = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# pre trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [preprocess(t) for t in list(df.text.values)]\n",
    "encoded_input = tokenizer_sentiment(text, return_tensors='pt', truncation=True, padding=True)\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = output[0].detach().numpy()\n",
    "scores = softmax(scores,axis=1)\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[:][::-1]\n",
    "\n",
    "df['sentiment']=[labels[x] for x in np.argmax(scores,axis=1)]\n",
    "df['negative']=scores[:,0]\n",
    "df['neutral']=scores[:,1]\n",
    "df['positive']=scores[:,2]\n",
    "\n",
    "\n",
    "# for printing\n",
    "# for t in range(scores.shape[0]):\n",
    "#     print(f'text: {df.text.iloc[t]}')\n",
    "#     for i in range(scores[0].shape[0]):\n",
    "#         l = labels[ranking[t][i]]\n",
    "#         s = scores[t][ranking[t][i]]\n",
    "#         print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task='emotion'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\" # load once\n",
    "\n",
    "tokenizer_emotion = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# pre trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [preprocess(t) for t in list(df.text.values)]\n",
    "encoded_input = tokenizer_emotion(text, return_tensors='pt', padding=True)\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = output[0].detach().numpy()\n",
    "scores = softmax(scores,axis=1)\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[:][::-1]\n",
    "\n",
    "df['emotion']=[labels[x] for x in np.argmax(scores,axis=1)]\n",
    "df['anger']=scores[:,0]\n",
    "df['joy']=scores[:,1]\n",
    "df['optimism']=scores[:,2]\n",
    "df['sadness']=scores[:,3]\n",
    "\n",
    "\n",
    "# for printing\n",
    "for t in range(3):\n",
    "    print(f'text: {df.text.iloc[t]}')\n",
    "    for i in range(scores[0].shape[0]):\n",
    "        l = labels[ranking[t][i]]\n",
    "        s = scores[t][ranking[t][i]]\n",
    "        print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tweets.csv',sep=';',index=False, quotechar='\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d0e0863b4dbc785a2b1bd227b176323538a9cabeeaebcabf04a1216aba68dd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
